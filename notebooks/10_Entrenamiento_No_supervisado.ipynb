{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datos y gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesado y modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warnings y display de la dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_colwidth\", 50)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio_actual = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_num_NS = pd.read_csv(os.path.join(directorio_actual, '..', 'data','processed', 'df_num_NS.csv'))\n",
    "df_NS = pd.read_csv(os.path.join(directorio_actual, '..', 'data','processed', 'df_NS.csv'))\n",
    "\n",
    "X = df_num_NS.drop(['price'],axis=1)\n",
    "y = df_num_NS['price']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalado de X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El numero de cluster, será 50 que es la cifra aproximada que necesita para predecir el 15% de las viviendas sin error\n",
    "kmeans = KMeans(n_clusters=50) \n",
    "clusters = kmeans.fit_predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo una columna los clusters asignados a cada registro\n",
    "df_num_NS['cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizo un train split del 15 por ciento\n",
    "df_train_NS, df_test_NS = train_test_split(df_num_NS,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grupoby por la columna cluster y le agrego la media del precio por cada cluster\n",
    "precio_medio_por_cluster = df_train_NS.groupby(['cluster'],as_index=False)['price'].agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creo un diccionario con cada cluster y su media de precio\n",
    "mapeo_cluster = dict(zip(precio_medio_por_cluster['cluster'], precio_medio_por_cluster['price']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creo la columna predicción, donde segun el cluster de cada registro, se le adjudica su media de precio\n",
    "df_num_NS['prediccion'] = df_num_NS['cluster'].map(mapeo_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 210.07014335864608\n",
      "MAPE: 0.18154241109243072\n",
      "RMSE: 324.36636963222253\n"
     ]
    }
   ],
   "source": [
    "print('MAE',mean_absolute_error(df_num_NS['price'],df_num_NS['prediccion']))\n",
    "print('MAPE:',mean_absolute_percentage_error(df_num_NS['price'],df_num_NS['prediccion']))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(df_num_NS['price'],df_num_NS['prediccion'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#función similar a las anteriores\n",
    "def calcular_alquiler_NS(tamaño,poblacion_distrito,parking,tipo_vivienda,piscina,habitaciones,baños):\n",
    "    \n",
    "    dicc_tipo = {'Estudio' : 1,'Piso' : 2,'Adosado' : 3,'Duplex' : 4,'Ático' : 5,'Casa pareada' : 6,'Chalet independiente' : 7}\n",
    "    dicc = {}\n",
    "    \n",
    "    dicc['size'] = tamaño\n",
    "\n",
    "    for i, pob_dis in enumerate(df_NS['poblacion / distrito']):\n",
    "        if pob_dis == poblacion_distrito:\n",
    "            for n, codigo_dist in enumerate(df_NS['precio_area / distrito']):\n",
    "                if n == i:\n",
    "                    dicc['precio_area / distrito'] = codigo_dist\n",
    "                    break\n",
    "    if parking == 'No':            \n",
    "        dicc['parking'] = 0\n",
    "    else:\n",
    "        dicc['parking'] = 1\n",
    "\n",
    "    for tipo,codigo in dicc_tipo.items():\n",
    "        if tipo == tipo_vivienda:\n",
    "            dicc['codigo_tipo'] = codigo\n",
    "\n",
    "    if piscina == 'No':            \n",
    "        dicc['piscina'] = 0\n",
    "    else:\n",
    "        dicc['piscina'] = 1\n",
    "\n",
    "    \n",
    "    dicc['total_rooms'] = habitaciones + baños\n",
    "    \n",
    "    \n",
    "    return(dicc)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creo una nueva predicción y la comvierto en dataframe\n",
    "nuevo_input = calcular_alquiler_NS(100,'Sevilla / Nervión','Si','Casa pareada','No',2,1)\n",
    "nuevo_input = pd.DataFrame([nuevo_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concateno la X, con la nueva predicción y reseteo indices creando la variable, nueva_df\n",
    "nueva_df = pd.concat([X,nuevo_input])\n",
    "nueva_df.reset_index(inplace=True)\n",
    "nueva_df.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#comenzamos con 250 cluster que es la cantidad, que hemos observado que da un erro muy bajo y no tarda mucho en la busqueda\n",
    "n = 250\n",
    "scaler = StandardScaler()\n",
    "nueva_df_scaled = scaler.fit_transform(nueva_df)\n",
    "kmeans = KMeans(n_clusters = n) \n",
    "clusters = kmeans.fit_predict(nueva_df_scaled)\n",
    "nueva_df['cluster'] = clusters\n",
    "\n",
    "'''mediante un bucle while, buscaremos el número de cluster necesario,\n",
    "para que el nuevo imput, no quede solo en un cluster y no obtenga precio,\n",
    "ya que al estar solo, no habria registros a los que sacarle la media'''\n",
    "while len(nueva_df[nueva_df['cluster'] == nueva_df['cluster'][len(nueva_df)-1]]) == 1:\n",
    "    n = n - 1\n",
    "    scaler = StandardScaler()\n",
    "    nueva_df_scaled = scaler.fit_transform(nueva_df)\n",
    "    kmeans = KMeans(n_clusters = n) \n",
    "    clusters = kmeans.fit_predict(nueva_df_scaled)\n",
    "    nueva_df['cluster'] = clusters\n",
    "    \n",
    "print(nueva_df['cluster'].nunique())\n",
    "print(len(nueva_df[nueva_df['cluster'] == nueva_df['cluster'][len(nueva_df)-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividimos la nueva dataframe, sacando así, el ultimo registro, que es nuestro nuevo imput\n",
    "nueva_df_train, nueva_df_test = train_test_split(nueva_df,test_size=1, shuffle=False)\n",
    "nueva_df_train = pd.concat([nueva_df_train,df_num_NS['price']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#al igual que en la evaluación, agrupamos por cluster, creamos diccionario y añadimos la columna predicciones\n",
    "precio_medio_por_cluster = nueva_df_train.groupby(['cluster'],as_index=False)['price'].agg('mean')\n",
    "mapeo_cluster = dict(zip(precio_medio_por_cluster['cluster'], precio_medio_por_cluster['price']))\n",
    "nueva_df_train['prediccion'] = nueva_df_train['cluster'].map(mapeo_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''recorremos la columna cluster de la dataframe anterior \n",
    "y cuando el cluster coincida con el del nuevo imput,\n",
    "le asignamos al nuevo input el precio medio de su cluster'''\n",
    "for i,cluster in enumerate(nueva_df_train['cluster']):\n",
    "    if cluster == nueva_df_test['cluster'][len(nueva_df)-1]:\n",
    "        prediccion = nueva_df_train['prediccion'][i]\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
